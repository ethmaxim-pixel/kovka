import OpenAI from "openai";
import { ENV } from "../_core/env";
import { getAIResponse } from "./ai";
import type { BotContext } from "./index";
import fs from "fs";
import path from "path";
import os from "os";

const openai = new OpenAI({
  apiKey: ENV.openaiApiKey,
  baseURL: ENV.openaiBaseUrl,
});

export async function handleVoiceMessage(ctx: BotContext) {
  const voice = ctx.message?.voice;
  const userId = ctx.from?.id;
  if (!voice || !userId) return;

  if (!ENV.openaiApiKey) {
    await ctx.reply("OpenAI API –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω. –ì–æ–ª–æ—Å–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã.");
    return;
  }

  // Show typing indicator
  await ctx.api.sendChatAction(ctx.chat!.id, "typing");

  let tempPath: string | null = null;

  try {
    // Download voice file from Telegram
    const file = await ctx.getFile();
    const filePath = file.file_path;

    if (!filePath) {
      await ctx.reply("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ.");
      return;
    }

    // Download file to temp directory
    const downloadUrl = `https://api.telegram.org/file/bot${ENV.telegramBotToken}/${filePath}`;
    const response = await fetch(downloadUrl);

    if (!response.ok) {
      await ctx.reply("–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è.");
      return;
    }

    const buffer = Buffer.from(await response.arrayBuffer());

    // Save to temp file
    tempPath = path.join(os.tmpdir(), `voice_${userId}_${Date.now()}.ogg`);
    fs.writeFileSync(tempPath, buffer);

    // Transcribe with Whisper
    const transcription = await openai.audio.transcriptions.create({
      file: fs.createReadStream(tempPath),
      model: "whisper-1",
      language: "ru",
      prompt: "–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç-–º–∞–≥–∞–∑–∏–Ω–∞ –∫–æ–≤–∞–Ω—ã—Ö –∏–∑–¥–µ–ª–∏–π",
    });

    const text = transcription.text;

    if (!text || text.trim().length === 0) {
      await ctx.reply("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.");
      return;
    }

    // Show transcription
    await ctx.reply(`üéô –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ: "${text}"`);

    // Send typing again for AI response
    await ctx.api.sendChatAction(ctx.chat!.id, "typing");

    // Get AI response based on transcribed text
    const aiResponse = await getAIResponse(userId, text);

    // Send images first
    for (const imageUrl of aiResponse.images) {
      try {
        await ctx.replyWithPhoto(imageUrl);
      } catch (imgErr) {
        console.error("[Bot Voice] Failed to send image:", imgErr);
      }
    }

    // Split long messages
    if (aiResponse.text.length > 4000) {
      const chunks = aiResponse.text.match(/.{1,4000}/gs) || [aiResponse.text];
      for (const chunk of chunks) {
        await ctx.reply(chunk);
      }
    } else {
      await ctx.reply(aiResponse.text);
    }
  } catch (error) {
    console.error("[Bot Voice] Error:", error);
    await ctx.reply("–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.");
  } finally {
    // Clean up temp file
    if (tempPath && fs.existsSync(tempPath)) {
      try {
        fs.unlinkSync(tempPath);
      } catch {}
    }
  }
}
